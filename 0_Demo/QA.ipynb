{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题分类解决方案\n",
    "\n",
    "---\n",
    "![image.png](https://github.com/Jie-Yuan/GithubPicture/raw/master/1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from pipe import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('./corpus.xlsx').fillna('')\n",
    "question_name = list(filter(lambda x: '问题' in x, df.columns))\n",
    "df = df[['分类名称'] + question_name]\n",
    "df['x'] = df.apply(lambda x: ''.join(x[1:]), 1)\n",
    "df['y'] = df['分类名称']\n",
    "data = df[['x', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyNLP(object):\n",
    "    def __init__(self, USER_DICT=None, STOP_WORDS_PATH=None):\n",
    "        jieba.load_userdict(USER_DICT)\n",
    "        self.STOP_WORDS_PATH = STOP_WORDS_PATH\n",
    "\n",
    "    def get_pure_corpus(self, corpus):\n",
    "        segment = jieba.cut(re.sub('[^0-9a-zA-Z\\u4e00-\\u9fa5]+', ' ', corpus))\n",
    "        return ' '.join(filter(lambda x: x not in self.stop_words, segment))\n",
    "\n",
    "    def get_key_words(self, sentence,\n",
    "                      allowPOS=['v', 'vg', 'vd', 'vn', 'n', 'nr', 'nr1', 'nr2', 'nrj', 'nrf', 'ns', 'nsf', 'nt', 'nz',\n",
    "                                'nl', 'ng'], topK=300):\n",
    "        params = {'sentence': sentence, 'topK': topK, 'allowPOS': allowPOS}\n",
    "        key_words = set(jieba.analyse.tfidf(**params) + jieba.analyse.textrank(**params))\n",
    "        return list(key_words)\n",
    "\n",
    "    @property\n",
    "    def stop_words(self):\n",
    "        with open(self.STOP_WORDS_PATH) as f:\n",
    "            stop_words = [line.strip() for line in f.readlines()] + [' ']\n",
    "        return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = '为什么阿里蚂蚁花呗、京东白条就不用上报征信？为什么花呗、京东白条就不上报征信？'\n",
    "USER_DICT = '/DATA/UserDict/finWordDict.txt'\n",
    "STOP_WORDS_PATH = \"/DATA/UserDict/stop_words.txt\"\n",
    "mynlp = MyNLP(USER_DICT, STOP_WORDS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_words = mynlp.get_key_words(' '.join(data.x), topK=200)\n",
    "oneHot = text.CountVectorizer()\n",
    "oneHot.fit(key_words)\n",
    "\n",
    "get_features = lambda x: oneHot.transform([' '.join(list(set(jieba.cut(x))))]).toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['xx'] = data.x.apply(get_features)\n",
    "feat_name = []\n",
    "for i in range(len(key_words)):\n",
    "    feat_name.append('xx_%s' %i)\n",
    "    data['xx_%s' %i] = data.xx.apply(lambda x: x[i])\n",
    "    \n",
    "le = LabelEncoder().fit(data.y)\n",
    "data['yy'] = le.transform(data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99        98\n",
      "          1       1.00      1.00      1.00        23\n",
      "          2       1.00      1.00      1.00        38\n",
      "          3       1.00      1.00      1.00         4\n",
      "          4       1.00      1.00      1.00         3\n",
      "          5       1.00      0.95      0.97        20\n",
      "          6       1.00      1.00      1.00         3\n",
      "          7       1.00      1.00      1.00         8\n",
      "          8       1.00      1.00      1.00         5\n",
      "          9       1.00      1.00      1.00         2\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00        23\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         6\n",
      "         14       1.00      1.00      1.00         6\n",
      "         15       1.00      1.00      1.00        38\n",
      "         16       1.00      1.00      1.00        10\n",
      "         17       1.00      1.00      1.00         6\n",
      "         18       1.00      1.00      1.00         2\n",
      "         19       1.00      1.00      1.00        16\n",
      "         20       1.00      1.00      1.00        25\n",
      "\n",
      "avg / total       1.00      1.00      1.00       340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data[feat_name].values\n",
    "y = data.yy.values\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)\n",
    "print(classification_report(y, lr.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@Pipe\n",
    "def get_class(x):\n",
    "    words = set(jieba.cut(x))\n",
    "    if words.intersection(key_words):\n",
    "        return le.classes_[lr.predict(get_features(x).reshape(1, -1))]\n",
    "    else:\n",
    "        print(\"请转人工客服！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['信用卡还款'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['礼品卡'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['易付宝账户'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['企业易付宝'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['任性付'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['任性付'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请转人工客服！\n"
     ]
    }
   ],
   "source": [
    "'上传信用卡不会泄露我信息么' | get_class\n",
    "'一个傻子在苏宁' | get_class\n",
    "'易付宝' | get_class\n",
    "'企业' | get_class\n",
    "'账户' | get_class\n",
    "'银行' | get_class\n",
    "'添利盈未到能提不' | get_class\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
