## 1. 分词
```python
import fool
import jieba

text = "一个傻子在苏宁"
fool.cut(text, True) 
# [['一个', '傻子', '在', '苏宁']]

jieba.lcut(text, cut_all=True) # list(jieba.cut(text, cut_all=True))
# ['一个', '傻子', '在', '苏宁']
```

## 2. 词性标注
```python
fool.pos_cut(text)
#[('一个', 'm'), ('傻子', 'n'), ('在', 'p'), ('北京', 'ns')]

jieba.posseg.lcut(text) # list(jieba.posseg.cut(text))
# [pair('一个', 'm'), pair('傻子', 'n'), pair('在', 'p'), pair('苏宁', 'ns')]
```

## 3. 实体识别
```python
words, ners = fool.analysis(text)
ners
# [(5, 8, 'location', '北京')]
```


## ...
```python
```
