{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessful Import Me!!!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "path = '/root/github/3_SpecialModule'\n",
    "os.sys.path.append(path)\n",
    "\n",
    "from Me import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "training_epochs = 20\n",
    "batch_size = 256\n",
    "display_step = 1\n",
    "examples_to_show = 10\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "tf_x = tf.placeholder(tf.float32, [None, 784])\n",
    "tf_y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# neural network layers\n",
    "# W1 = tf.Variable(tf.truncated_normal([784, 300], stddev=0.1))\n",
    "# b1 = tf.Variable(tf.zeros([300]))\n",
    "# W2 = tf.Variable(tf.zeros([300, 10]))\n",
    "# b2 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "hidden1 = tf.layers.dense(inputs=tf_x, units=300, activation=tf.nn.relu)\n",
    "hidden1_drop = tf.layers.dropout(hidden1, rate=0.75)\n",
    "hidden2 = tf.layers.dense(inputs=hidden1_drop, units=10, activation=tf.nn.relu)\n",
    "\n",
    "output = tf.layers.dense(inputs=hidden2, units=10, activation=tf.nn.softmax)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss = tf.losses.sparse_softmax_cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss + Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(-tf.reduce_sum(tf_y* tf.log(output), reduction_indices=[1]))\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "accuracy = tf.metrics.accuracy(labels=tf.argmax(tf_y, axis=1), predictions=tf.argmax(output, axis=1),)[1] # accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()                                                                 # control training and others\n",
    "init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "sess.run(init)     # initialize var in graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch: 0001, loss = 0.773938477, accuracy = 0.564872980\n",
      "===> Epoch: 0002, loss = 0.516848683, accuracy = 0.698424697\n",
      "===> Epoch: 0003, loss = 0.398218900, accuracy = 0.754946709\n",
      "===> Epoch: 0004, loss = 0.478600293, accuracy = 0.788496614\n",
      "===> Epoch: 0005, loss = 0.346799552, accuracy = 0.811284304\n",
      "===> Epoch: 0006, loss = 0.319895744, accuracy = 0.827583492\n",
      "===> Epoch: 0007, loss = 0.243363157, accuracy = 0.840307891\n",
      "===> Epoch: 0008, loss = 0.258068085, accuracy = 0.850549459\n",
      "===> Epoch: 0009, loss = 0.225546896, accuracy = 0.859009922\n",
      "===> Epoch: 0010, loss = 0.228101641, accuracy = 0.866068542\n",
      "Optimization Finished!\n",
      "Accuracy: 0.867266595\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 10\n",
    "batch_size = 256\n",
    "display_step = 1\n",
    "traindata = mnist.train\n",
    "testdata = mnist.test\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "# Train model\n",
    "for step in range(training_epochs):\n",
    "    for i in range(total_batch):\n",
    "        batch_x, batch_y = traindata.next_batch(batch_size)\n",
    "        _, l, acc, pred = sess.run([train_step, loss, accuracy, output],{tf_x: batch_x, tf_y: batch_y, keep_prob: 0.75})\n",
    "    if step % display_step == 0:\n",
    "        print(\"===> Epoch: {:04d}, loss = {:0.9f}, accuracy = {:0.9f}\".format(step + 1, l, acc))\n",
    "print (\"Optimization Finished!\")\n",
    "\n",
    "# Test model\n",
    "# correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(tf_y, 1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# accuracy = tf.metrics.accuracy(labels=tf.argmax(tf_y, axis=1), predictions=tf.argmax(y, axis=1),)[1] # 与上等价，前面已做\n",
    "\n",
    "print(\"Accuracy: {:0.9f}\".format(sess.run(accuracy, {tf_x: testdata.images, tf_y: testdata.labels, keep_prob: 1.0})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 多一层循环\n",
    "# 一轮相当于：total_batch*batch_size\n",
    "# 一层循环的时候，training_epochs*batch_size/mnist.train.num_examples相当于迭代（epoch）次数"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "156px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
